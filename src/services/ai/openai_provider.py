"""
OpenAI å…¼å®¹ Provider å®ç°
æ”¯æŒ GPT-4, DeepSeek, MiMo (Xiaomi) ç­‰å…¼å®¹ OpenAI æ¥å£çš„æ¨¡å‹
"""
import logging
import json
import os
from pathlib import Path
from typing import Dict, Any, Optional, List
from http import HTTPStatus

try:
    import openai
    from openai import OpenAI, APIError
except ImportError:
    openai = None
    OpenAI = None
    APIError = None

from .base_provider import BaseAIProvider

logger = logging.getLogger(__name__)

class OpenAIProvider(BaseAIProvider):
    """OpenAI å…¼å®¹æ¨¡å‹æä¾›è€…"""
    
    def __init__(self, api_key: str, model_id: str = None, **kwargs):
        self.client = None
        self.base_url = kwargs.get("base_url")
        # å¦‚æœæ²¡æœ‰æŒ‡å®š base_url ä½† provider æ˜¯ openaiï¼Œä½¿ç”¨é»˜è®¤
        if not self.base_url and "openai" in self.__class__.__name__.lower():
            self.base_url = "https://api.openai.com/v1"
        
        # âœ… ä¿å­˜é¢„è®¾é…ç½®ï¼ˆthinking, temperature ç­‰ï¼‰ï¼Œåœ¨ chat() æ—¶è‡ªåŠ¨åº”ç”¨
        self.preset_config = {k: v for k, v in kwargs.items() if k not in ['base_url']}
            
        super().__init__(api_key, model_id, **kwargs)
        
        # å†æ¬¡ç¡®ä¿åˆå§‹åŒ–ï¼ˆè™½ç„¶ _validate_config å¯èƒ½å·²ç»è°ƒç”¨è¿‡ï¼‰
        if not self.client:
            self._init_client()

    def _init_client(self):
        """åˆå§‹åŒ– OpenAI Client"""
        if OpenAI is None:
            return
            
        if self.api_key:
            # è‡ªåŠ¨ä¿®å¤ Base URL: ç§»é™¤æœ«å°¾çš„ /chat/completions
            if self.base_url and self.base_url.endswith("/chat/completions"):
                self.base_url = self.base_url.replace("/chat/completions", "")
                
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            logger.info(f"OpenAI Client initialized. BaseURL: {self.base_url}, Model: {self.model_id}")

    def get_default_model(self) -> str:
        return "gpt-4o"
    
    def _validate_config(self):
        """éªŒè¯ OpenAI é…ç½®"""
        if OpenAI is None:
            raise ImportError("è¯·å…ˆå®‰è£… openai åº“: pip install openai")
        
        if not self.api_key:
            raise ValueError("OpenAI API Key ä¸èƒ½ä¸ºç©º")
            
        if not self.client:
            self._init_client()

    def _prepare_extra_body(self, kwargs: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡ extra_body å‚æ•°ï¼Œç”¨äºå¤„ç†éæ ‡å‡†å‚æ•°ï¼ˆå¦‚ thinkingï¼‰"""
        extra_body = {}
        
        # å¤„ç† thinking å‚æ•° (MiMo ç‰¹æœ‰)
        # æ”¯æŒä» config ä¸­ç›´æ¥ä¼ å…¥ {"thinking": {"type": "enabled"}}
        if "thinking" in kwargs:
            extra_body["thinking"] = kwargs["thinking"]
        elif "thinking_type" in kwargs: #æ‰“å¹³çš„å‚æ•°æ”¯æŒ
             extra_body["thinking"] = {"type": kwargs["thinking_type"]}
             
        return extra_body

    def chat(self, query: str, context: str = "", system_prompt: str = None, **kwargs) -> str:
        """
        èŠå¤©æ¥å£
        æ”¯æŒ OpenAI å…¼å®¹æ¥å£ï¼Œæ”¯æŒ thinking mode
        """
        self._validate_config()

        # 1. æ„å»º System Prompt
        default_system_prompt = """
ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹ Memexã€‚
CORE RULES:
1. STRICT GROUNDING: å›ç­”å¿…é¡»åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
2. NO EXTERNAL KNOWLEDGE FOR SPECIFICS: ä¸è¦ç¼–é€ å…·ä½“æ•°æ®ã€‚
3. CITATION: å°½å¯èƒ½å¼•ç”¨æ¥æºã€‚
"""
        final_system_prompt = system_prompt if system_prompt else default_system_prompt

        # 2. æ„å»º Messages
        messages = [
            {"role": "system", "content": final_system_prompt},
        ]
        
        if context:
            user_content = f"ä¸Šä¸‹æ–‡ä¿¡æ¯:\n{context}\n\nç”¨æˆ·é—®é¢˜: {query}"
        else:
            user_content = query
            
        messages.append({"role": "user", "content": user_content})

        # 3. å‡†å¤‡å‚æ•°
        # æå–æ ‡å‡†å‚æ•°
        temperature = kwargs.get("temperature", 0.7)
        max_tokens = kwargs.get("max_tokens", kwargs.get("max_completion_tokens"))
        top_p = kwargs.get("top_p", 0.95)
        frequency_penalty = kwargs.get("frequency_penalty", 0)
        presence_penalty = kwargs.get("presence_penalty", 0)
        
        # âœ… åˆå¹¶é¢„è®¾é…ç½®å’Œè°ƒç”¨æ—¶ä¼ å…¥çš„å‚æ•°
        merged_kwargs = {**self.preset_config, **kwargs}
        
        # å‡†å¤‡ extra_body (ç”¨äº thinking ç­‰éæ ‡å‚æ•°)
        extra_body = self._prepare_extra_body(merged_kwargs)
        
        # è®°å½•æ˜¯å¦å¯ç”¨äº† thinking æ¨¡å¼
        if extra_body.get("thinking"):
            logger.info(f"ğŸ§  Thinking mode enabled: {extra_body['thinking']}")

        try:
            # 4. è°ƒç”¨ API
            logger.info(f"â”â”â” PHASE 3: REASONING â”â”â”")
            logger.info(f"ğŸ“¤ Request: model={self.model_id}, thinking={bool(extra_body.get('thinking'))}")
            logger.debug(f"Params: temp={temperature}, extra_body={extra_body}")
            
            completion = self.client.chat.completions.create(
                model=self.model_id,
                messages=messages,
                temperature=temperature,
                max_completion_tokens=max_tokens, # OpenAI SDK v1.x uses max_completion_tokens for o1/newer models
                top_p=top_p,
                frequency_penalty=frequency_penalty,
                presence_penalty=presence_penalty,
                stream=False, # æš‚ä¸æ”¯æŒæµå¼ï¼Œå›  BaseProvider æ¥å£é™åˆ¶
                extra_body=extra_body if extra_body else None
            )

            # 5. å¤„ç†å“åº”
            choice = completion.choices[0]
            message = choice.message
            content = message.content or ""
            
            # å¤„ç† Reasoning Content (æ€è€ƒè¿‡ç¨‹)
            # MiMo/DeepSeek å¯èƒ½åœ¨ message.reasoning_content ä¸­è¿”å›
            reasoning_content = getattr(message, 'reasoning_content', None)
            
            if reasoning_content:
                logger.info(f"ğŸ§  Thinking Process: {len(reasoning_content)} chars")
                if not content:
                    return f"[Thinking Process]\n{reasoning_content}"
            
            # âœ… è®°å½•æœ€ç»ˆå›å¤
            logger.info(f"âœ… Response: {len(content)} chars")
            logger.info(f"â”â”â” PHASE 3: COMPLETE â”â”â”")
            
            return content

        except Exception as e:
            logger.error(f"OpenAI Chat request failed: {e}", exc_info=True)
            return f"AI Service Error: {str(e)}"

    def analyze_file(self, file_path: Path, context_text: str = None, **kwargs) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶å†…å®¹ (Review/Tagging)"""
        self._validate_config()
        
        file_name = file_path.name
        content_preview = context_text if context_text else f"æ–‡ä»¶å: {file_name}\n(æ— æ³•æå–ç›´æ¥æ–‡æœ¬)"
        if len(content_preview) > 30000:
            content_preview = content_preview[:30000] + "\n...(truncated)"
            
        # å¤ç”¨ Dashscope çš„ Prompt é€»è¾‘ï¼Œä¿æŒä¸€è‡´æ€§
        import datetime
        now = datetime.datetime.now()
        file_ext = Path(file_name).suffix
        
        from src.core.prompt_manager import prompt_manager
        
        # Use simple default if DB is offline (rare)
        default_prompt = """
ä½ æ˜¯æ™ºèƒ½æ–‡ä»¶å½’æ¡£åŠ©æ‰‹ã€‚è¯·åŸºäºå†…å®¹ç”Ÿæˆç»“æ„åŒ– JSONã€‚
**CRITICAL: You MUST include "suggested_filename" at the root.**

æ–‡ä»¶å: {filename}
å†…å®¹é¢„è§ˆ:
{content_text}

**JSON Schema**:
{{
  "suggested_filename": "YYYYMMDD_æ ¸å¿ƒå†…å®¹æ‘˜è¦{file_ext}",
  "semantic": {{
    "category": "Medical/Finance/Work/Personal/Unsorted",
    "tags": ["tag1", "tag2"],
    "summary": "ç®€çŸ­æ‘˜è¦ï¼ˆ<=50å­—ï¼‰"
  }},
  "structured": {{
    "date": "YYYY-MM-DD",
    "money": null
  }}
}}
"""
        prompt_template = prompt_manager.get("system.file_analyze", default=default_prompt)
        
        # Format the prompt using keyword arguments to match the template placeholders
        prompt = prompt_template.format(
            current_time=now.strftime("%Y-%m-%d %H:%M:%S"),
            filename=file_name,
            content_source="File Upload",
            content_text=content_preview,
            today_str=now.strftime("%Y%m%d"),
            file_ext=file_ext,
            now=now # For backward compat if template uses {now.year}
        )
        messages = [
            {"role": "system", "content": "You are a helpful assistant capable of JSON output."},
            {"role": "user", "content": prompt}
        ]
        
        try:
            completion = self.client.chat.completions.create(
                model=self.model_id,
                messages=messages,
                response_format={"type": "json_object"}, # å°è¯•å¼ºåˆ¶ JSON
                temperature=0.1,
            )
            content = completion.choices[0].message.content
            
            # ç®€å•çš„ JSON è§£æä¸å®¹é”™
            try:
                # å°è¯•æå– JSON å—
                import re
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                    # ç¡®ä¿ç»“æ„å®Œæ•´
                    if "semantic" not in data: data["semantic"] = {}
                    if "structured" not in data: data["structured"] = {}
                    return data
                else:
                    return {"semantic": {"summary": content[:100], "category": "Unsorted"}}
            except json.JSONDecodeError:
                logger.error(f"Failed to parse JSON from OpenAI response: {content}")
                return {"semantic": {"summary": "Analysis failed (JSON Error)", "category": "Unsorted"}}
                
        except Exception as e:
            logger.error(f"OpenAI Analyze File failed: {e}")
            return {"semantic": {"summary": f"Error: {e}", "category": "Unsorted"}}

    def generate_text(self, prompt: str, **kwargs) -> str:
        """é€šç”¨æ–‡æœ¬ç”Ÿæˆ"""
        self._validate_config()
        try:
            completion = self.client.chat.completions.create(
                model=self.model_id,
                messages=[{"role": "user", "content": prompt}],
                temperature=kwargs.get("temperature", 0.7)
            )
            return completion.choices[0].message.content
        except Exception as e:
            logger.error(f"OpenAI Generate Text failed: {e}")
            return f"Error: {str(e)}"
